{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Applied Neural Networks - Exercises \n", "\n", "**NOTICE:**\n", "1. You are allowed to work in groups of up to three people but **have to document** your group's\\\n", " members in the top cell of your notebook.\n", "2. **Comment your code**, explain what you do (refer to the slides). It will help you understand the topics\\\n", " and help me understand your thinking progress. Quality of comments will be graded. \n", "3. **Discuss** and analyze your results, **write-down your learnings**. These exercises are no programming\\\n", " exercises it is about learning and getting a touch for these methods. Such questions might be asked in the\\\n", " final exams. \n", " 4. Feel free to **experiment** with these methods. Change parameters think about improvements, write down\\\n", " what you learned. This is not only about collecting points for the final grade, it is about understanding\\\n", "  the methods. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1 - Data Normalization and Standardization\n", "\n", "\n", "**Summary:** In this exercise you will implement the min-max normalization and standardization and compare it to\\\n", "sklearn's implementation. It is important to remember, that we always normalize or standardize for all samples\\\n", " over a single feature dimension.\n", "\n", "\n", "**Provided Code:** In the cell below I have provided you with a sample code to initialize some dummy data.\\\n", "The parameter ```n_samples``` defines the number of samples we have in the training set (the number of $x_i$)\\\n", "while ```n_features``` defines the number of dimensions of each sample feature vector. \n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Implement the MinMax Normalization and Standardization. \n", "2. Use the ```MinMaxScaler``` and ```StandardScaler``` from sklearn to verify your results. \n"]}, {"cell_type": "code", "execution_count": 170, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import make_regression\n", "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n", "\n", "x,y = make_regression(n_samples=10, n_features=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2 - Softmax\n", "\n", "**Summary:** In this exercise you will implement the softmax activation using the naive and numerically\\\n", "more stable log-sum variation. \n", "\n", "\n", "**Provided Code:** In the cell below there is some sample code that generates sample inputs. \n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Implement the softmax function using the naive approach. \n", "2. Implement the softmax function using the log-sum trick. \n", "3. Compare your two implementations for numerical stability\\\n", "(experiment with different values of std) and verify\n", "your results using ```tf.nn.softmax```\n", "\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["import numpy as np \n", "import tensorflow as tf\n", "\n", "mu = 0\n", "std = 10\n", "xi = mu + std * np.random.randn(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 3 - Chess Endgames\n", "\n", "**Summary:** In this exercise your task is to predict the optimal depth-of-win for white in   \n", "chess-endgames. In particular, we will focus on **king-rook** vs. **king** endgames. The   \n", "possible outcomes are either a **draw** or a **number of moves** for white to win (0 to 16). \n", "\n", "\n", "**Provided Code:** The code below loads the original (*unprepared*) raw dataset.   \n", "You will have to prepare it accordingly to be used with neural nets. \n", "\n", "The structure of each row in the dataset is:\n", "1. White King column (a-h)\n", "2. White King row (1-8)\n", "3. White Rook column (a-h)\n", "4. White Rook row (1-8)\n", "5. Black King column (a-h)\n", "6. Black King row (1-8)\n", "7. Optimal depth-of-win for White in 0 to 16 moves or a draw\n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Train a neural net to predict the depth-of-win (or draw) given a board position\n", "    * You will have to prepare your data accordingly to make it compatible   \n", "    with neural nets. Think about input and output encodings, normalization or standardization. \n", "    * Decide how you will model this problem as either regression or classification task. \n", "    * Build a fully connected neural net with appropriate configuration and loss and train it. \n", "    * Use appropriate cross-validation for training and validation (it is enough to use two datasets)\n", "2. Explain in writing:\n", "    * How and why did you prepared the data?\n", "    * How did you model the problem task?\n", "    * What is your neural network architecture/configuration/loss?\n", "    * Plot your loss while training.\n", "    * Interpret and explain your results. \n", "    \n", "\n"]}, {"cell_type": "code", "execution_count": 97, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Der Befehl \"wget\" ist entweder falsch geschrieben oder\n", "konnte nicht gefunden werden.\n"]}], "source": ["!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/condition_monitoring.pickle -P ../data\n", "import pickle\n", "with open('../data/chess_endgames.pickle', 'rb') as fd:\n", "    chess_endgames = pickle.load(fd)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Solution 3 - Chess Endgames"]}, {"cell_type": "code", "execution_count": 63, "metadata": {}, "outputs": [], "source": ["col_lookup  = {'a': 0, 'b' : 1, 'c': 2, 'd' : 3, 'e': 4, 'f': 5, 'g':6, 'h':7}\n", "class_lookup = {'draw' : 0, 'zero' : 1, 'one': 2, 'two' : 3, 'three' : 4, 'four': 5, \n", "                'five': 6, 'six' : 7, 'seven' : 8, 'eight' : 9, 'nine' : 10,\n", "                'ten' : 11, 'eleven' : 12, 'twelve' : 13, 'thirteen' : 14, \n", "                'fourteen' : 15, 'fifteen' : 16, 'sixteen' : 17}\n", "\n", "\n", "y = rows[:,-1]\n", "x = rows[:, 0:-1]\n", "\n", "for row in x:\n", "    row[0] = col_lookup[row[0]]\n", "    row[2] = col_lookup[row[2]]\n", "    row[4] = col_lookup[row[4]]\n", "\n", "\n", "for i in range(len(y)):\n", "    y[i] = class_lookup[y[i]]\n", "    \n", "\n", "x = x.astype('uint32')\n", "y = y.astype('uint32')\n", "y = tf.keras.utils.to_categorical(y)\n", "    \n", "\n", "    "]}, {"cell_type": "code", "execution_count": 67, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)"]}, {"cell_type": "code", "execution_count": 74, "metadata": {}, "outputs": [], "source": ["# normalize input data\n", "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n", "scaler = MinMaxScaler()\n", "scaler.fit(x_train)\n", "\n", "x_train = scaler.transform(x_train)\n", "x_test = scaler.transform(x_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model: \"sequential_8\"\n", "_________________________________________________________________\n", " Layer (type)                Output Shape              Param #   \n", "=================================================================\n", " dense_28 (Dense)            (None, 256)               1792      \n", "                                                                 \n", " dense_29 (Dense)            (None, 256)               65792     \n", "                                                                 \n", " dense_30 (Dense)            (None, 256)               65792     \n", "                                                                 \n", " dense_31 (Dense)            (None, 256)               65792     \n", "                                                                 \n", " dense_32 (Dense)            (None, 256)               65792     \n", "                                                                 \n", " dense_33 (Dense)            (None, 18)                4626      \n", "                                                                 \n", "=================================================================\n", "Total params: 269,586\n", "Trainable params: 269,586\n", "Non-trainable params: 0\n", "_________________________________________________________________\n"]}], "source": ["from tensorflow.keras.regularizers import L2\n", "from tensorflow.keras.layers import Dense, Input, Dropout\n", "from tensorflow.keras.layers import LeakyReLU\n", "\n", "model = tf.keras.Sequential()\n", "model.add(Input(shape=(6)))\n", "model.add(Dense(256, activation='relu'))\n", "model.add(Dense(256, activation='relu'))\n", "model.add(Dense(256, activation='relu'))\n", "model.add(Dense(256, activation='relu'))\n", "model.add(Dense(256, activation='relu'))\n", "model.add(Dense(18,  activation='softmax'))\n", "\n", "\n", "model.summary()\n", "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n", "callbacks = [\n", "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n", "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n", "                              patience=25, min_lr=0.00001)\n", "\n", "]\n", "\n", "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"]}, {"cell_type": "code", "execution_count": 110, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Epoch 1/100\n", " 10/614 [..............................] - ETA: 3s - loss: 0.1436 - accuracy: 0.9469 "]}, {"name": "stdout", "output_type": "stream", "text": ["614/614 [==============================] - 2s 3ms/step - loss: 0.0952 - accuracy: 0.9692 - val_loss: 0.5580 - val_accuracy: 0.8692\n", "Epoch 2/100\n", "614/614 [==============================] - 2s 3ms/step - loss: 0.0883 - accuracy: 0.9701 - val_loss: 0.5397 - val_accuracy: 0.8735\n", "Epoch 3/100\n", "473/614 [======================>.......] - ETA: 0s - loss: 0.0818 - accuracy: 0.9718"]}, {"ename": "", "evalue": "", "output_type": "error", "traceback": ["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}], "source": ["history = model.fit(x_train,y_train, validation_data=(x_test, y_test), epochs=100, batch_size=32)"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"ename": "NameError", "evalue": "name 'history' is not defined", "output_type": "error", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[1;32mc:\\Work\\Lectures\\OneDrive - FH Vorarlberg\\LVs\\Notebook-DB\\src\\NN\\Applied-NN\\Applied-NN-Exercises-Solutions.ipynb Cell 37\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/Lectures/OneDrive%20-%20FH%20Vorarlberg/LVs/Notebook-DB/src/NN/Applied-NN/Applied-NN-Exercises-Solutions.ipynb#Y134sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Work/Lectures/OneDrive%20-%20FH%20Vorarlberg/LVs/Notebook-DB/src/NN/Applied-NN/Applied-NN-Exercises-Solutions.ipynb#Y134sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/Lectures/OneDrive%20-%20FH%20Vorarlberg/LVs/Notebook-DB/src/NN/Applied-NN/Applied-NN-Exercises-Solutions.ipynb#Y134sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/Lectures/OneDrive%20-%20FH%20Vorarlberg/LVs/Notebook-DB/src/NN/Applied-NN/Applied-NN-Exercises-Solutions.ipynb#Y134sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend([\u001b[39m'\u001b[39m\u001b[39mtrain-loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval-loss\u001b[39m\u001b[39m'\u001b[39m])\n", "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"]}, {"ename": "", "evalue": "", "output_type": "error", "traceback": ["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}], "source": ["import matplotlib.pyplot as plt \n", "\n", "plt.plot(history.history['loss'])\n", "plt.plot(history.history['val_loss'])\n", "plt.legend(['train-loss', 'val-loss'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"celltoolbar": "Edit Metadata", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.18"}}, "nbformat": 4, "nbformat_minor": 2}