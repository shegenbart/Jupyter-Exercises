{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Applied Neural Networks - Exercises \n", "\n", "**NOTICE:**\n", "1. You are allowed to work in groups of up to three people but **have to document** your group's\\\n", " members in the top cell of your notebook.\n", "2. **Comment your code**, explain what you do (refer to the slides). It will help you understand the topics\\\n", " and help me understand your thinking progress. Quality of comments will be graded. \n", "3. **Discuss** and analyze your results, **write-down your learnings**. These exercises are no programming\\\n", " exercises it is about learning and getting a touch for these methods. Such questions might be asked in the\\\n", " final exams. \n", " 4. Feel free to **experiment** with these methods. Change parameters think about improvements, write down\\\n", " what you learned. This is not only about collecting points for the final grade, it is about understanding\\\n", "  the methods. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1 - Data Normalization and Standardization\n", "\n", "\n", "**Summary:** In this exercise you will implement the min-max normalization and standardization and compare it to\\\n", "sklearn's implementation. It is important to remember, that we always normalize or standardize for all samples\\\n", " over a single feature dimension.\n", "\n", "\n", "**Provided Code:** In the cell below I have provided you with a sample code to initialize some dummy data.\\\n", "The parameter ```n_samples``` defines the number of samples we have in the training set (the number of $x_i$)\\\n", "while ```n_features``` defines the number of dimensions of each sample feature vector. \n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Implement the MinMax Normalization and Standardization. \n", "2. Use the ```MinMaxScaler``` and ```StandardScaler``` from sklearn to verify your results. \n"]}, {"cell_type": "code", "execution_count": 170, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import make_regression\n", "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n", "\n", "x,y = make_regression(n_samples=10, n_features=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2 - Softmax\n", "\n", "**Summary:** In this exercise you will implement the softmax activation using the naive and numerically\\\n", "more stable log-sum variation. \n", "\n", "\n", "**Provided Code:** In the cell below there is some sample code that generates sample inputs. \n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Implement the softmax function using the naive approach. \n", "2. Implement the softmax function using the log-sum trick. \n", "3. Compare your two implementations for numerical stability\\\n", "(experiment with different values of std) and verify\n", "your results using ```tf.nn.softmax```\n", "\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["import numpy as np \n", "import tensorflow as tf\n", "\n", "mu = 0\n", "std = 10\n", "xi = mu + std * np.random.randn(10)"]}], "metadata": {"celltoolbar": "Edit Metadata", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.18"}}, "nbformat": 4, "nbformat_minor": 2}