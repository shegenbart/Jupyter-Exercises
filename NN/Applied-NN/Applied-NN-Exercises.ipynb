{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Applied Neural Networks - Exercises \n", "\n", "**NOTICE:**\n", "1. You are allowed to work in groups of up to three people but **have to document** your group's\\\n", " members in the top cell of your notebook.\n", "2. **Comment your code**, explain what you do (refer to the slides). It will help you understand the topics\\\n", " and help me understand your thinking progress. Quality of comments will be graded. \n", "3. **Discuss** and analyze your results, **write-down your learnings**. These exercises are no programming\\\n", " exercises it is about learning and getting a touch for these methods. Such questions might be asked in the\\\n", " final exams. \n", " 4. Feel free to **experiment** with these methods. Change parameters think about improvements, write down\\\n", " what you learned. This is not only about collecting points for the final grade, it is about understanding\\\n", "  the methods. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1 - Data Normalization and Standardization\n", "\n", "\n", "**Summary:** In this exercise you will implement the min-max normalization and standardization and compare it to\\\n", "sklearn's implementation. It is important to remember, that we always normalize or standardize for all samples\\\n", " over a single feature dimension.\n", "\n", "\n", "**Provided Code:** In the cell below I have provided you with a sample code to initialize some dummy data.\\\n", "The parameter ```n_samples``` defines the number of samples we have in the training set (the number of $x_i$)\\\n", "while ```n_features``` defines the number of dimensions of each sample feature vector. \n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Implement the MinMax Normalization and Standardization. \n", "2. Use the ```MinMaxScaler``` and ```StandardScaler``` from sklearn to verify your results. \n"]}, {"cell_type": "code", "execution_count": 170, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import make_regression\n", "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n", "\n", "x,y = make_regression(n_samples=10, n_features=5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2 - Softmax\n", "\n", "**Summary:** In this exercise you will implement the softmax activation using the naive and numerically\\\n", "more stable log-sum variation. \n", "\n", "\n", "**Provided Code:** In the cell below there is some sample code that generates sample inputs. \n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Implement the softmax function using the naive approach. \n", "2. Implement the softmax function using the log-sum trick. \n", "3. Compare your two implementations for numerical stability\\\n", "(experiment with different values of std) and verify\n", "your results using ```tf.nn.softmax```\n", "\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["import numpy as np \n", "import tensorflow as tf\n", "\n", "mu = 0\n", "std = 10\n", "xi = mu + std * np.random.randn(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 3 - Chess Endgames\n", "\n", "**Summary:** In this exercise your task is to predict the optimal depth-of-win for white in   \n", "chess-endgames. In particular, we will focus on **king-rook** vs. **king** endgames. The   \n", "possible outcomes are either a **draw** or a **number of moves** for white to win (0 to 16). \n", "\n", "\n", "**Provided Code:** The code below loads the original (*unprepared*) raw dataset.   \n", "You will have to prepare it accordingly to be used with neural nets. \n", "\n", "The structure of each row in the dataset is:\n", "1. White King column (a-h)\n", "2. White King row (1-8)\n", "3. White Rook column (a-h)\n", "4. White Rook row (1-8)\n", "5. Black King column (a-h)\n", "6. Black King row (1-8)\n", "7. Optimal depth-of-win for White in 0 to 16 moves or a draw\n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Train a neural net to predict the depth-of-win (or draw) given a board position\n", "    * You will have to prepare your data accordingly to make it compatible   \n", "    with neural nets. Think about input and output encodings, normalization or standardization. \n", "    * Decide how you will model this problem as either regression or classification task. \n", "    * Build a fully connected neural net with appropriate configuration and loss and train it. \n", "    * Use appropriate cross-validation for training and validation (it is enough to use two datasets)\n", "2. Explain in writing:\n", "    * How and why did you prepared the data?\n", "    * How did you model the problem task?\n", "    * What is your neural network architecture/configuration/loss?\n", "    * Plot your loss while training.\n", "    * Interpret and explain your results. \n", "    \n", "\n"]}, {"cell_type": "code", "execution_count": 97, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Der Befehl \"wget\" ist entweder falsch geschrieben oder\n", "konnte nicht gefunden werden.\n"]}], "source": ["!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/condition_monitoring.pickle -P ../data\n", "import pickle\n", "with open('../data/chess_endgames.pickle', 'rb') as fd:\n", "    chess_endgames = pickle.load(fd)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"celltoolbar": "Edit Metadata", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.18"}}, "nbformat": 4, "nbformat_minor": 2}