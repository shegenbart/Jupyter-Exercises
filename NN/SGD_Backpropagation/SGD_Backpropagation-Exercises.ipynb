{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# SGD and Backpropagation - Exercises \n", "\n", "**NOTICE:**\n", "1. You are allowed to work in groups of up to three people but **have to document** your group's\\\n", " members in the top cell of your notebook.\n", "2. **Comment your code**, explain what you do (refer to the slides). It will help you understand the topics\\\n", " and help me understand your thinking progress. Quality of comments will be graded. \n", "3. **Discuss** and analyze your results, **write-down your learnings**. These exercises are no programming\\\n", " exercises it is about learning and getting a touch for these methods. Such questions might be asked in the\\\n", " final exams. \n", " 4. Feel free to **experiment** with these methods. Change parameters think about improvements, write down\\\n", " what you learned. This is not only about collecting points for the final grade, it is about understanding\\\n", "  the methods. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1 - Gradient Descent\n", "\n", "\n", "**Summary:** In this exercise you will implement the gradient descent algorithm. It will\\\n", "help you to gain a better understanding on how neural networks are trained. \n", "\n", "\n", "**Provided Code:** In the cell below I have provided you with a function ``f()`` and the first\\\n", "derivative of ``f()`` denoted ``dfdx()``.\n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Implement the gradient descent algorithm. \n", "2. Plot and analyze your results. \n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["#@title **Provided Code:** ``f()`` and ``dfdx()`` function. \n", "\n", "import matplotlib.pyplot as plt \n", "import numpy as np \n", "\n", "\n", "def f(x):\n", "    return x**2\n", "\n", "def dfdx(x):\n", "    return 2*x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2 - Gradient Descent with Momentum\n", "\n", "\n", "**Summary:** In this exercise you will improve the gradient descent algorithm from the\\\n", "previous exercise to act using the momentum idea.\n", "\n", "\n", "**Provided Code:** In the cell below I have provided you with a function ``g()``.\n", "\n", "\n", "**Your Tasks in this exercise:**\n", "1. Calculate the gradient of ``g()`` with respect to x. \n", "2. Extend your implementation of gradient descent with momentum. \n", "3. Try to find a minimum of ``g()``.\n", "4. Answer the following questions:\n", "    * What is a good value fo $\\alpha$?\n", "    * What is the impact of the initialization of your optimization (the starting point)?\n", "    * Why do neural networks produce different results if trained multiple times?\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# A non-convex function. \n", "#\n", "def g(x):\n", "    return np.exp(-(x**2)) * np.sin(x**3)"]}], "metadata": {"celltoolbar": "Edit Metadata", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.18"}}, "nbformat": 4, "nbformat_minor": 2}