{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Computer Vision - Special Topics \n", "\n", "This notebook contains exercises for the Computer Vision Special Topics material. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1 - Transfer Learning\n", "\n", "**Summary:**\n", "In this exercise we will use transfer learning using a neural networks outputs as features for a SVM. \n", "\n", "**Data**: \n", "We will use a subset of the cifar100 dataset (I call it cifar20). You are provided with a pre-trained model on the cifar80 (the other categories in cifar100) that reaches a test \n", "accuracy of approximately 63% on the cifar80 dataset. Execute the cells below to prepare the dataset and load the pretrained model (```pretrained_model```). Notice that the pretrained model was trained\n", "for a 80-class problem.  \n", "\n", "**Your Tasks in this exercise:**\n", "\n", "1. Use transfer learning to train a SVM classifier using the features extracted by the pretrained model \n", "    * Extract features using a suitable layer in the pretrained model. Notice you might want to use the ```tf.keras.Model(inputs=, outputs=)``` class to access the outputs of each layer easily. \n", "    * Train a SVM classifier (use sklearn) on the features extracted using the training data (```X_train_cifar20```)\n", "    * Evaluate the performance of your classifier on the features extracted using the test data (```X_test_cifar20```)\n", "    * Discuss your results. \n", "\n"]}, {"cell_type": "code", "execution_count": 508, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import numpy as np \n", "\n", "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar100.load_data()\n", "X_train = X_train / 255.0\n", "X_test = X_test / 255.0\n", "\n", "cifar20_labels = np.array([60, 72, 65, 97, 18, 47, 58, 51, 84,  2, 90,  6, 38, 35, 70, 89, 24, 86, 36, 32])\n", "cifar20_label_mapping = {60 : 0, 72: 1, 65 : 2, 97 : 3, 18 : 4, 47 : 5, 58 : 6, 51 : 7, 84 : 8,  2 : 9, 90 : 10, \n", "                          6 : 11, 38 : 12, 35 :13, 70 : 14, 89 : 15, 24 : 16, 86 : 17, 36: 18, 32 : 19}\n", "\n", "X_train_cifar20 = X_train[np.isin(Y_train, cifar20_labels).ravel(),:,:]\n", "Y_train_cifar20 = Y_train[np.isin(Y_train, cifar20_labels).ravel()]\n", "\n", "X_test_cifar20 = X_test[np.isin(Y_test, cifar20_labels).ravel(),:,:]\n", "Y_test_cifar20 = Y_test[np.isin(Y_test, cifar20_labels).ravel()]\n", "\n", "\n", "Y_train_cifar20_remapped = []\n", "for y in Y_train_cifar20.ravel():\n", "    y_mapped = cifar20_label_mapping[y]\n", "    Y_train_cifar20_remapped.append(y_mapped)\n", "Y_train_cifar20 = np.array(Y_train_cifar20_remapped)\n", "\n", "Y_test_cifar20_remapped = []\n", "for y in Y_test_cifar20.ravel():\n", "    y_mapped = cifar20_label_mapping[y]\n", "    Y_test_cifar20_remapped.append(y_mapped)\n", "Y_test_cifar20 = np.array(Y_test_cifar20_remapped)\n"]}, {"cell_type": "code", "execution_count": 532, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2023-03-22 15:44:13--  https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5\n", "Resolving github.com (github.com)... 140.82.121.3\n", "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n", "HTTP request sent, awaiting response... 302 Found\n", "Location: https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5 [following]\n", "--2023-03-22 15:44:13--  https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5\n", "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n", "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 34199344 (33M) [application/octet-stream]\n", "Saving to: \u00e2\u20ac\u02dc../data/cifar80_resnet_best.h5.3\u00e2\u20ac\u2122\n", "\n", "cifar80_resnet_best 100%[===================>]  32.61M  87.0MB/s    in 0.4s    \n", "\n", "2023-03-22 15:44:14 (87.0 MB/s) - \u00e2\u20ac\u02dc../data/cifar80_resnet_best.h5.3\u00e2\u20ac\u2122 saved [34199344/34199344]\n", "\n"]}], "source": ["!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5 -P ../data\n", "pretrained = tf.keras.models.load_model('../data/cifar80_resnet_best.h5')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2 - Fine Tuning \n", "\n", "**Summary:**\n", "In this exercise we will use fine tuning to adapt a neural network to a new dataset. \n", "\n", "**Data**: \n", "We will use a subset of the cifar100 dataset (I call it cifar20). You are provided with a pre-trained model on the cifar80 (the other categories in cifar100) that reaches a test \n", "accuracy of approximately 63% on the cifar80 dataset. Execute the cells below to prepare the dataset and load the pretrained model (```pretrained_model```). Notice that the pretrained model was trained\n", "for a 80-class problem.  \n", "\n", "**Your Tasks in this exercise:**\n", "\n", "1. Fine tune the pre-trained model. \n", "    * Create a new model using the functional keras API that uses the pretrained model in a 20-class classification problem. Notice you will need to ignore/remove the final layer and replace it with a suitable layer. \n", "    * Train your fine-tuning model:\n", "        * Freeze all layers borrowed from the pre-trained model and and fine tune the model\n", "        * Fine-tune all layers of the new model \n", "        * Compare both models. \n", "    * Plot and discuss your results. \n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2023-03-22 15:35:13--  https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5\n", "Resolving github.com (github.com)... 140.82.121.3\n", "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n", "HTTP request sent, awaiting response... 302 Found\n", "Location: https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5 [following]\n", "--2023-03-22 15:35:13--  https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5\n", "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n", "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 34199344 (33M) [application/octet-stream]\n", "Saving to: \u00e2\u20ac\u02dc../data/cifar80_resnet_best.h5.2\u00e2\u20ac\u2122\n", "\n", "cifar80_resnet_best 100%[===================>]  32.61M  62.7MB/s    in 0.5s    \n", "\n", "2023-03-22 15:35:14 (62.7 MB/s) - \u00e2\u20ac\u02dc../data/cifar80_resnet_best.h5.2\u00e2\u20ac\u2122 saved [34199344/34199344]\n", "\n"]}], "source": ["!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5 -P ../data\n", "pretrained_model = tf.keras.models.load_model('../data/cifar80_resnet_best.h5')\n", "\n", "import tensorflow as tf\n", "import numpy as np \n", "\n", "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar100.load_data()\n", "X_train = X_train / 255.0\n", "X_test = X_test / 255.0\n", "\n", "cifar20_labels = np.array([60, 72, 65, 97, 18, 47, 58, 51, 84,  2, 90,  6, 38, 35, 70, 89, 24, 86, 36, 32])\n", "cifar20_label_mapping = {60 : 0, 72: 1, 65 : 2, 97 : 3, 18 : 4, 47 : 5, 58 : 6, 51 : 7, 84 : 8,  2 : 9, 90 : 10, \n", "                          6 : 11, 38 : 12, 35 :13, 70 : 14, 89 : 15, 24 : 16, 86 : 17, 36: 18, 32 : 19}\n", "\n", "X_train_cifar20 = X_train[np.isin(Y_train, cifar20_labels).ravel(),:,:]\n", "Y_train_cifar20 = Y_train[np.isin(Y_train, cifar20_labels).ravel()]\n", "\n", "X_test_cifar20 = X_test[np.isin(Y_test, cifar20_labels).ravel(),:,:]\n", "Y_test_cifar20 = Y_test[np.isin(Y_test, cifar20_labels).ravel()]\n", "\n", "Y_train_cifar20_remapped = []\n", "for y in Y_train_cifar20.ravel():\n", "    y_mapped = cifar20_label_mapping[y]\n", "    Y_train_cifar20_remapped.append(y_mapped)\n", "Y_train_cifar20 = np.array(Y_train_cifar20_remapped)\n", "\n", "Y_test_cifar20_remapped = []\n", "for y in Y_test_cifar20.ravel():\n", "    y_mapped = cifar20_label_mapping[y]\n", "    Y_test_cifar20_remapped.append(y_mapped)\n", "Y_test_cifar20 = np.array(Y_test_cifar20_remapped)\n", "\n", "Y_train_cifar_20_one_hot = tf.keras.utils.to_categorical(Y_train_cifar20_remapped)\n", "Y_test_cifar_20_one_hot = tf.keras.utils.to_categorical(Y_test_cifar20_remapped)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 3 - Regularization Techniques\n", "\n", "**Summary:**\n", "In this exercise we study different regularization techniques used to train neural networks. \n", "\n", "**Data**: \n", "In this exercise we will use the cifar10 dataset. I have provided you with a cell to load and preprocess the dataset below. I also provided you with a very simple base-CNN\n", "(```cnn_base```).\n", "\n", "**Your Tasks in this exercise:**\n", "\n", "1. Train and evaluate the base-CNN \n", "    * Train the base-CNN on the training portion of the dataset\n", "    * Make sure that the test part of the data is used after each epoch to predict the test accuracy \n", "    * Record the history of your training (```hist = cnn_base.fit(...)```) and plot your results after training is finished. You can access the training accuracy values\n", "    via ```hist.history['acc']``` and the test accuracy values via ```hist.history['val_acc']```.\n", "    * Explain the results. \n", "\n", "2. Train and evaluate the base-CNN using L1-Regularization\n", "    * Create a new cell and copy the base-CNN. Add a kernel regularizer and bias regularizer using L1-Regularization (where does it make sense?)\n", "    * Train the L1-CNN, plot the results and compare the results to the base-CNN. \n", "    * Explain the results. \n", "\n", "3. Train and evaluate the base-CNN using L2-Regularization\n", "    * Create a new cell and copy the base-CNN. Add a kernel regularizer and bias regularizer using L2-Regularization (where does it make sense?)\n", "    * Train the L2-CNN, plot the results and compare the results to the base-CNN. \n", "    * Explain the results. \n", "\n", "4. Train and evaluate the base-CNN using Dropout\n", "    * Create a new cell and copy the base-CNN. Add Dropout layers (where does it make sense?)\n", "    * Train the Dropout-CNN, plot the results and compare the results to the base-CNN. \n", "    * Explain the results. "]}, {"cell_type": "code", "execution_count": 439, "metadata": {}, "outputs": [], "source": ["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n", "x_train = x_train / 255.0\n", "x_test = x_test / 255.0 \n", "\n", "y_test = tf.keras.utils.to_categorical(y_test, 10)\n", "y_train = tf.keras.utils.to_categorical(y_train, 10)"]}, {"cell_type": "code", "execution_count": 448, "metadata": {}, "outputs": [], "source": ["# Use this simple CNN as your basis for adding regularization.\n", "#\n", "import tensorflow as tf\n", "from tensorflow.keras.layers import Conv2D, InputLayer, MaxPooling2D, GlobalAveragePooling2D, Softmax, Dense, Flatten, Dropout\n", "\n", "cnn_base = tf.keras.Sequential()\n", "cnn_base.add(InputLayer(input_shape=(32,32,3)))\n", "cnn_base.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n", "cnn_base.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n", "cnn_base.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n", "cnn_base.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n", "cnn_base.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n", "cnn_base.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n", "cnn_base.add(Flatten())\n", "cnn_base.add(Dense(256, activation='relu'))\n", "cnn_base.add(Dense(10, activation='softmax'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 4 - Residual Learning\n", "\n", "**Summary:**\n", "In this exercise we will create two neural networks that take an image with shape $(32,32,3)$ as input and provide us with the same image as output $(32,32,3)$. Consequently we try to learn a mapping $\\mathcal{H}(x) := x$, which is known as the identity function. The identity function is a trivial function in mathematics but can be hard to learn using convolution operations. \n", "\n", "**Data**: \n", "In this exercise we will use the cifar100 dataset. I have provided you with a cell to load and preprocess the dataset below. \n", "\n", "**Your Tasks in this exercise:**\n", "\n", "1. ConvNet\n", "    * Create a convolutional neural network (with 2 BatchNormalization and Conv2D layers, using only InputLayer, Conv2D and BatchNormalization as layers), which accepts images of shape $(32,32,3)$ and returns an image of shape $(32,32,3)$. Notice: You will have to use the functional keras API to do so (see slides).\n", "    * Train your neural network (use only 2 epochs) with a suitable loss function.  \n", "2. ResNet\n", "    * Create a convolutional neural network using two identity blocks of a ResNet, which accepts images of shape $(32,32,3)$ and returns an image of shape $(32,32,3)$.\n", "    * Train your neural network (using only 2 epochs) with a suitable loss function. \n", "3. Analyze your Results\n", "    * Use the ```evaluate()``` function of your keras model to predict the MSE of both trained nets.\n", "    * Use some images from ```X_test``` and feed them into your models. Visualize the results. \n", "    * Compare the results, explain the difference between the results, explain what happened. \n", "\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 410, "metadata": {}, "outputs": [], "source": ["(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")\n", "X_train = X_train / 255.0\n", "X_test = X_test / 255.0"]}], "metadata": {"celltoolbar": "Edit Metadata", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 2}