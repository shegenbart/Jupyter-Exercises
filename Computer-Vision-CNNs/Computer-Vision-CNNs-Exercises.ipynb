{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Computer Vision CNNs Notebook\n", "\n", "This notebook contains exercises for the computer vision CNNs material."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--2023-03-15 13:12:37--  https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/kth_tips.pbz2\n", "Resolving github.com (github.com)... 140.82.121.4\n", "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n", "HTTP request sent, awaiting response... 302 Found\n", "Location: https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/kth_tips.pbz2 [following]\n", "--2023-03-15 13:12:37--  https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/kth_tips.pbz2\n", "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n", "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n", "HTTP request sent, awaiting response... 200 OK\n", "Length: 26821274 (26M) [application/octet-stream]\n", "Saving to: \u00e2\u20ac\u02dc../data/kth_tips.pbz2.2\u00e2\u20ac\u2122\n", "\n", "kth_tips.pbz2.2     100%[===================>]  25.58M  70.1MB/s    in 0.4s    \n", "\n", "2023-03-15 13:12:38 (70.1 MB/s) - \u00e2\u20ac\u02dc../data/kth_tips.pbz2.2\u00e2\u20ac\u2122 saved [26821274/26821274]\n", "\n"]}], "source": ["import tensorflow as tf\n", "import pickle, bz2\n", "from sklearn.model_selection import train_test_split\n", "\n", "!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/kth_tips.pbz2 -P ../data\n", "\n", "\n", "with bz2.BZ2File('../data/kth_tips.pbz2', 'rb') as fd:\n", "    kth_dataset = pickle.load(fd)\n", "\n", "X_train, X_test, Y_train, Y_test = train_test_split(kth_dataset['X'], kth_dataset['Y'], random_state=12345)\n", "Y_train = tf.keras.utils.to_categorical(Y_train)\n", "Y_test = tf.keras.utils.to_categorical(Y_test)\n", "\n", "X_train = X_train / 255\n", "X_test = X_test / 255"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1 - Classify Image Dataset with Conventional Neural Network\n", "\n", "I have provided you with an image dataset (the same we used in the Local Binary Patterns exercise). Your images are in \n", "X_train, X_test while youre labels are in Y_train, Y_test. \n", "\n", "Your job is to train a neural network on the pixel values to classify the images. To do so:\n", "* Reshape the images from $(n,200,200)$ to $(n,40000)$\n", "* Create a neural network model using keras\n", "* Train your neural network on the (X_train, Y_train) and validate on the (X_test, Y_test) data. \n", "* Compare your results with the LBP-results (if you have them)\n", "* Explain what happened\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2: Convolutional Layer\n", "\n", "In the cell below, I have provided you with a very simple CNN consisting only of a single convolutional layer. \n", "You can access the weights (kernels) of a keras model by accessing the layer with:\n", "\n", "```python \n", "kernel_list = cnn.layers[0].get_weights() # This gives us a list of kernels in the layer\n", "```\n", "\n", "\n", "Experiment with different parameters for ```filters, kernel_size``` and ```input_shape``` and have \n", "a look at the kernels to get a solid understanding of how these kernels a CNN uses look like. \n", "\n", "Answer the following questions:\n", "* How are the kernel dimensions influenced by the input dimensions?\n", "* How is the number of parameters in the network influenced by the input dimension, the kernel size and the number of filters?\n", "* Explain and summarize your findings. "]}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model: \"sequential_20\"\n", "_________________________________________________________________\n", " Layer (type)                Output Shape              Param #   \n", "=================================================================\n", " conv2d_26 (Conv2D)          (None, 124, 124, 1)       76        \n", "                                                                 \n", " conv2d_27 (Conv2D)          (None, 122, 122, 2)       20        \n", "                                                                 \n", "=================================================================\n", "Total params: 96\n", "Trainable params: 96\n", "Non-trainable params: 0\n", "_________________________________________________________________\n"]}], "source": ["from tensorflow.keras import Sequential\n", "from tensorflow.keras.layers import Conv2D, InputLayer\n", "\n", "\n", "\n", "cnn = Sequential()\n", "cnn.add(InputLayer(input_shape=(128,128,3)))\n", "cnn.add(Conv2D(filters=1, kernel_size=(5,5)))\n", "cnn.add(Conv2D(filters=2, kernel_size=(3,3)))\n", "\n", "cnn.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 3 - Pooling Layer\n", "\n", "Create a convolutional neural network with two convolution layers followed by pooling layers (use either max pooling or average pooling).\n", "\n", "Experiment with different values for ```pool_size, strides``` and study how the output shape is affected. \n", "Answer the following questions:\n", "* What is the difference in output size between max pooling and average pooling? Why?\n", "* What is the impact on the receptive field of a convolutional layer following a pooling layer?\n", "* How is the amount of parameters affected by a pooling layer?\n", " "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 4: Flatten and GlobalAveragePooling\n", "\n", "In this exercise we will study two methods we can use to transfrom multi-dimensional feature maps to one-dimensional feature maps as used as input for Dense layers. \n", "\n", "1. Create a convolution neural network using two convolutional layers. \n", "    * Use a Flatten layer to transform your multi-dimensional feature map to a one-dimensional feature map. \n", "    * Add a Dense output layer for a classification problem with 10 classes.\n", "    * Where is the majority of the weights in your network architecture?\n", "    * How could this influence the training of your network?\n", "\n", "2. Create a convolution neural network using two convolutional layers. \n", "    * Use a GlobalAveragePooling2D layer to transform your multi-dimensional feature map to a one-dimensional feature map. \n", "    * Create a network architecture for a classification problem with 10 classes without using a Dense layer. \n", "    * Where is the majority of weights in your network architecture?\n", "    * How could this influence the training of your network?\n", "\n", "    \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 5: Classification using CNNS\n", "\n", "\n", "In the first exercise in this notebook we already downloaded and prepared the KTH-TIPS dataset we used previously for classification. We saw that using a conventional NN\n", "did not work very well in this scenario. \n", "\n", "1. Create a CNN of your choice to train a classifier for the provided dataset. \n", "    * Train on (X_train, Y_train), Validate on (X_test, Y_test) (you can specify validation_data in the ```model.fit()``` function of keras)\n", "2. Compare using Flatten() and GlobalAveragePooling() for feeding your features into Dense layers\n", "    * How does it effect the number of parameters, the accuracy of your results and the time used to train the models?\n", "3. What is the highest accuracy you can reach with the smallest amount of parameters? \n", "\n", "\n"]}, {"cell_type": "code", "execution_count": 41, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model: \"sequential_16\"\n", "_________________________________________________________________\n", " Layer (type)                Output Shape              Param #   \n", "=================================================================\n", " conv2d_55 (Conv2D)          (None, 198, 198, 16)      160       \n", "                                                                 \n", " max_pooling2d_46 (MaxPoolin  (None, 66, 66, 16)       0         \n", " g2D)                                                            \n", "                                                                 \n", " conv2d_56 (Conv2D)          (None, 64, 64, 32)        4640      \n", "                                                                 \n", " max_pooling2d_47 (MaxPoolin  (None, 21, 21, 32)       0         \n", " g2D)                                                            \n", "                                                                 \n", " conv2d_57 (Conv2D)          (None, 19, 19, 32)        9248      \n", "                                                                 \n", " flatten (Flatten)           (None, 11552)             0         \n", "                                                                 \n", " dense_25 (Dense)            (None, 256)               2957568   \n", "                                                                 \n", " dense_26 (Dense)            (None, 10)                2560      \n", "                                                                 \n", "=================================================================\n", "Total params: 2,974,176\n", "Trainable params: 2,974,176\n", "Non-trainable params: 0\n", "_________________________________________________________________\n"]}], "source": ["cnn_flatten.summary()"]}], "metadata": {"celltoolbar": "Edit Metadata", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}}, "nbformat": 4, "nbformat_minor": 2}