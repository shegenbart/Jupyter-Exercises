{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Boosting Exercises"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["'wget' is not recognized as an internal or external command,\n", "operable program or batch file.\n"]}], "source": ["# Download data\n", "#\n", "!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/baseball.pickle -P ../data\n", "\n", "#Imports, Helper Functions and Data Structures\n", "#\n", "\n", "import numpy as np\n", "import numpy as np\n", "import pickle\n", "\n", "from dataclasses import dataclass\n", "def load_dataset(filename):\n", "    with open(filename, 'rb') as fd:\n", "        dataset = pickle.load(fd)\n", "    return dataset\n", "\n", "# Baseball dataset\n", "#\n", "@dataclass\n", "class Dataset:\n", "    Description: str\n", "    Attributes: list()\n", "    Targets: list()\n", "    X: np.array\n", "    Y: np.array\n", "        \n", "        "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Exercise 1:\n", "\n", "* Load the baseball dataset using ```load_dataset(../data/baseball.pickle)```.\n", "* Have a look at the dataset, there are multiple fields such as Attributes, Targets, Description, ...\n", "* Train a boosted classifier that predicts whether a player will end up in the hall-of-fame or not (you can use the ```accuracy_score()``` method from sklearn to easily do this. \n", "* Experiment with the number of estimators (n_estimators), what is the impact of this paramater and what does it do?\n", "\n", "**Notice:**\n", "\n", "Do not train and test on the same set of data, this will result in too high accuracy. Instead use cross validation such as:\n", "\n", "```python\n", "from sklearn.model_selection import train_test_split\n", "X_train, X_test, Y_train, Y_test = train_test_split(baseball.X, baseball.Y)\n", "```\n", "\n", "Then train on ```X_train, Y_train``` and predict using ```X_test and Y_test```."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Exercise 2:\n", "\n", "* Use ```X,Y = gen_data()``` to generate a set of random features and labels. \n", "* Train a boosted classifier and compare the training-accuracy and test-accuracy. \n", "* Explain what happened. \n"]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "def gen_data(num_samples=100):\n", "\n", "    std = 10\n", "    mean = 0\n", "\n", "    X = std * np.random.uniform(0, 1, (num_samples, 2)) + mean\n", "    Y = np.zeros(num_samples)\n", "    Y[0:int(num_samples/2)] = 1\n", "\n", "    plt.figure()\n", "    plt.scatter(X[0:int(num_samples/2),0], X[0:int(num_samples/2),1])\n", "    plt.scatter(X[int(num_samples/2):-1,0], X[int(num_samples/2):-1,1])\n", "    plt.legend(['Class-1', 'Class-2'])\n", "    return X,Y"]}], "metadata": {"celltoolbar": "Edit Metadata", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.12"}, "vscode": {"interpreter": {"hash": "71e3996440a4286f4b5430a3d4d1ae66fa68d894e5edac3334c7ebe5f98b7546"}}}, "nbformat": 4, "nbformat_minor": 2}